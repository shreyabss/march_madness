{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a761c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/shreya/opt/anaconda3/lib/python3.9/site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in /Users/shreya/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in /Users/shreya/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9fa9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the stuff you need\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Slider, Dropdown, Button\n",
    "from bokeh.plotting import output_file, show\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearColorMapper, ColorBar, BasicTicker, HoverTool, ColumnDataSource\n",
    "from bokeh.palettes import Viridis256, Magma256\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import transform\n",
    "from matplotlib import pyplot\n",
    "from numpy import loadtxt\n",
    "from pandas.errors import PerformanceWarning\n",
    "import warnings\n",
    "#Tensor flow was not working on jupiter?\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1458ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in every file of the dataset here, then return them as a dictionary\n",
    "## Returns dict {'file name' : Pandas Dataframe}\n",
    "def load_data():\n",
    "    csvs = {}\n",
    "    ## Change the path for your own machine...\n",
    "    directory = os.path.join(\"/Users/cs573/project/march-machine-learning-mania-2023\")\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                ## Change the path for your own machine...\n",
    "                csvs[file] = pd.read_csv(f'/Users/cs573/project/march-machine-learning-mania-2023/{file}', encoding='cp1252')\n",
    "                print(f'Read file {file}, it has columns {csvs[file].columns}, it has shape {csvs[file].shape}')\n",
    "    return csvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf8d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Caculate season averages and totals and add them to the MTeams csv dataset, \n",
    "\n",
    "def calculate_averages(s, csvs, file):\n",
    "    season = s\n",
    "    regular_season = csvs[file]\n",
    "    season_s = regular_season.loc[regular_season['Season'] == season]\n",
    "    teams = csvs['MTeams.csv'].iloc[:, 0:2].copy()\n",
    "    \n",
    "    ## Block of code that calculates the season total of each statistic for the winning team of each game\n",
    "    teams['OPPFGM_W'] = season_s.groupby('WTeamID')['LFGM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPPOINTS_W'] = season_s.groupby('WTeamID')['LScore'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGA_W'] = season_s.groupby('WTeamID')['LFGA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGM3_W'] = season_s.groupby('WTeamID')['LFGM3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGA3_W'] = season_s.groupby('WTeamID')['LFGA3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPOR_W'] = season_s.groupby('WTeamID')['LOR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPDR_W'] = season_s.groupby('WTeamID')['LDR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPAST_W'] = season_s.groupby('WTeamID')['LAst'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPTO_W'] = season_s.groupby('WTeamID')['LTO'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPSTL_W'] = season_s.groupby('WTeamID')['LStl'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPBLK_W'] = season_s.groupby('WTeamID')['LBlk'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPPF_W'] = season_s.groupby('WTeamID')['LPF'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFTM_W'] = season_s.groupby('WTeamID')['LFTM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFTA_W'] = season_s.groupby('WTeamID')['LFTA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGM_W'] = season_s.groupby('WTeamID')['WFGM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['POINTS_W'] = season_s.groupby('WTeamID')['WScore'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGA_W'] = season_s.groupby('WTeamID')['WFGA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGM3_W'] = season_s.groupby('WTeamID')['WFGM3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGA3_W'] = season_s.groupby('WTeamID')['WFGA3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FTM_W'] = season_s.groupby('WTeamID')['WFTM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FTA_W'] = season_s.groupby('WTeamID')['WFTA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OR_W'] = season_s.groupby('WTeamID')['WOR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['DR_W'] = season_s.groupby('WTeamID')['WDR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['AST_W'] = season_s.groupby('WTeamID')['WAst'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['TO_W'] = season_s.groupby('WTeamID')['WTO'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['STL_W'] = season_s.groupby('WTeamID')['WStl'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['BLK_W'] = season_s.groupby('WTeamID')['WBlk'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['PF_W'] = season_s.groupby('WTeamID')['WPF'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    \n",
    "    ## Calculates the season total of each statistic for the losing team of each game\n",
    "    teams['OPPFGM_L'] = season_s.groupby('LTeamID')['WFGM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPPOINTS_L'] = season_s.groupby('LTeamID')['WScore'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGA_L'] = season_s.groupby('LTeamID')['WFGA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGM3_L'] = season_s.groupby('LTeamID')['WFGM3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFGA3_L'] = season_s.groupby('LTeamID')['WFGA3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPOR_L'] = season_s.groupby('LTeamID')['WOR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPDR_L'] = season_s.groupby('LTeamID')['WDR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPAST_L'] = season_s.groupby('LTeamID')['WAst'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPTO_L'] = season_s.groupby('LTeamID')['WTO'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPSTL_L'] = season_s.groupby('LTeamID')['WStl'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPBLK_L'] = season_s.groupby('LTeamID')['WBlk'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPPF_L'] = season_s.groupby('LTeamID')['WPF'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFTM_L'] = season_s.groupby('LTeamID')['WFTM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OPPFTA_L'] = season_s.groupby('LTeamID')['WFTA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGM_L'] = season_s.groupby('LTeamID')['LFGM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['POINTS_L'] = season_s.groupby('LTeamID')['LScore'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGA_L'] = season_s.groupby('LTeamID')['LFGA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGM3_L'] = season_s.groupby('LTeamID')['LFGM3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FGA3_L'] = season_s.groupby('LTeamID')['LFGA3'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FTM_L'] = season_s.groupby('LTeamID')['LFTM'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['FTA_L'] = season_s.groupby('LTeamID')['LFTA'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['OR_L'] = season_s.groupby('LTeamID')['LOR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['DR_L'] = season_s.groupby('LTeamID')['LDR'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['AST_L'] = season_s.groupby('LTeamID')['LAst'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['TO_L'] = season_s.groupby('LTeamID')['LTO'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['STL_L'] = season_s.groupby('LTeamID')['LStl'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['BLK_L'] = season_s.groupby('LTeamID')['LBlk'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['PF_L'] = season_s.groupby('LTeamID')['LPF'].sum().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    \n",
    "    # Since each team has cumulative data for games the lose and for games they win, to get season totals\n",
    "    # must combine the stats from wins with losses.\n",
    "    teams['OPPFGM'] = teams['OPPFGM_W'] + teams['OPPFGM_L']\n",
    "    teams['OPPPOINTS'] = teams['OPPPOINTS_W'] + teams['OPPFGM_L']\n",
    "    teams['OPPFGA'] = teams['OPPFGA_W'] + teams['OPPFGA_L']\n",
    "    teams['OPPFGM3'] = teams['OPPFGM3_W'] + teams['OPPFGM3_L']\n",
    "    teams['OPPFGA3'] = teams['OPPFGA3_W'] + teams['OPPFGA3_L']\n",
    "    teams['OPPOR'] = teams['OPPOR_L'] + teams['OPPOR_W']\n",
    "    teams['OPPDR'] = teams['OPPDR_L'] + teams['OPPDR_W']\n",
    "    teams['OPPAST'] = teams['OPPAST_L'] + teams['OPPAST_W']\n",
    "    teams['OPPTO'] = teams['OPPTO_L'] + teams['OPPTO_W']\n",
    "    teams['OPPSTL'] = teams['OPPSTL_L'] + teams['OPPSTL_W']\n",
    "    teams['OPPBLK'] = teams['OPPBLK_L'] + teams['OPPBLK_W']\n",
    "    teams['OPPPF'] = teams['OPPPF_L'] + teams['OPPPF_W']\n",
    "    teams['OPPFTM'] = teams['OPPFTM_L'] + teams['OPPFTM_W']\n",
    "    teams['OPPFTA'] = teams['OPPFTA_W'] + teams['OPPFTA_L']\n",
    "    teams['FGM'] = teams['FGM_W'] + teams['FGM_L']\n",
    "    teams['POINTS'] = teams['POINTS_W'] + teams['FGM_L']\n",
    "    teams['FGA'] = teams['FGA_W'] + teams['FGA_L']\n",
    "    teams['FGM3'] = teams['FGM3_W'] + teams['FGM3_L']\n",
    "    teams['FGA3'] = teams['FGA3_W'] + teams['FGA3_L']\n",
    "    teams['OR'] = teams['OR_L'] + teams['OR_W']\n",
    "    teams['DR'] = teams['DR_L'] + teams['DR_W']\n",
    "    teams['AST'] = teams['AST_L'] + teams['AST_W']\n",
    "    teams['TO'] = teams['TO_L'] + teams['TO_W']\n",
    "    teams['STL'] = teams['STL_L'] + teams['STL_W']\n",
    "    teams['BLK'] = teams['BLK_L'] + teams['BLK_W']\n",
    "    teams['PF'] = teams['PF_L'] + teams['PF_W']\n",
    "    teams['FTM'] = teams['FTM_L'] + teams['FTM_W']\n",
    "    teams['FTA'] = teams['FTA_W'] + teams['FTA_L']\n",
    "    \n",
    "    # Count the amount of games the team wins and losses\n",
    "    teams['WINS'] = season_s['WTeamID'].value_counts().sort_index().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['LOSSES'] = season_s['LTeamID'].value_counts().sort_index().reindex(np.arange(1101, 1478, 1), fill_value=0).values\n",
    "    teams['GAMES'] = teams['WINS'] + teams['LOSSES']\n",
    "    \n",
    "    # Advanced stats\n",
    "    teams['POSSESSIONS'] = 0.5 * (teams['FGA'] - teams['OR'] + teams['TO'] + (0.475 * teams['FTA']))\n",
    "    teams['OPPPOSSESSIONS'] = 0.5 * (teams['OPPFGA'] - teams['OPPOR'] + teams['OPPTO'] + (0.475 * teams['OPPFTA']))\n",
    "    teams['ORTG'] = (100 / (teams['POSSESSIONS'] + teams['OPPPOSSESSIONS'])) * teams['POINTS']\n",
    "    teams['DRTG'] = (100 / (teams['POSSESSIONS'] + teams['OPPPOSSESSIONS'])) * teams['OPPPOINTS']\n",
    "    \n",
    "    #Get season averages\n",
    "    teams['OPPFGMPG'] = teams['OPPFGM'] / teams['GAMES']\n",
    "    teams['OPPPOINTSPG'] = teams['OPPPOINTS'] / teams['GAMES']\n",
    "    teams['OPPFGAPG'] = teams['OPPFGA'] / teams['GAMES']\n",
    "    teams['OPPFGM3PG'] = teams['OPPFGM3'] / teams['GAMES']\n",
    "    teams['OPPFGA3PG'] = teams['OPPFGA3'] / teams['GAMES']\n",
    "    teams['OPPORPG'] = teams['OPPOR'] / teams['GAMES']\n",
    "    teams['OPPDRPG'] = teams['OPPDR'] / teams['GAMES']\n",
    "    teams['OPPASTPG'] = teams['OPPAST'] / teams['GAMES']\n",
    "    teams['OPPTOPG'] = teams['OPPTO'] / teams['GAMES']\n",
    "    teams['OPPSTLPG'] = teams['OPPSTL'] / teams['GAMES']\n",
    "    teams['OPPBLKPG'] = teams['OPPBLK'] / teams['GAMES']\n",
    "    teams['OPPPFPG'] = teams['OPPPF'] / teams['GAMES']\n",
    "    teams['OPPFTMPG'] = teams['OPPFTM'] / teams['GAMES']\n",
    "    teams['OPPFTAPG'] = teams['OPPFTA'] / teams['GAMES']\n",
    "    teams['FGMPG'] = teams['FGM'] / teams['GAMES']\n",
    "    teams['POINTSPG'] = teams['POINTS'] / teams['GAMES']\n",
    "    teams['FGAPG'] = teams['FGA'] / teams['GAMES']\n",
    "    teams['FGM3PG'] = teams['FGM3'] / teams['GAMES']\n",
    "    teams['FGA3PG'] = teams['FGA3'] / teams['GAMES']\n",
    "    teams['ORPG'] = teams['OR'] / teams['GAMES']\n",
    "    teams['DRPG'] = teams['DR'] / teams['GAMES']\n",
    "    teams['ASTPG'] = teams['AST'] / teams['GAMES']\n",
    "    teams['TOPG'] = teams['TO'] / teams['GAMES']\n",
    "    teams['STLPG'] = teams['STL'] / teams['GAMES']\n",
    "    teams['BLKPG'] = teams['BLK'] / teams['GAMES']\n",
    "    teams['PFPG'] = teams['PF'] / teams['GAMES']\n",
    "    teams['FTMPG'] = teams['FTM'] / teams['GAMES']\n",
    "    teams['FTAPG'] = teams['FTA'] / teams['GAMES']\n",
    "\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451c259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This creates an interactive graph, allowing the user to visualize the statsitcs which correlate to\n",
    "## tournament success.\n",
    "def calculate_tourney_wins_and_graph(reg, tou):\n",
    "    reg['TOURNWINS'] = tou['WINS']\n",
    "    reg['TOURNLS'] = tou['LOSSES']\n",
    "\n",
    "    menu = []\n",
    "    for x in reg:\n",
    "        menu.append((x, x))\n",
    "\n",
    "    output_file(\"js_on_change.html\")\n",
    "    reg['x'] = reg['ORTG']\n",
    "    reg['y'] = reg['DRTG']\n",
    "    reg['c'] = reg['POINTS']\n",
    "\n",
    "    label = {'xl': 'Offensive Rating', 'yl': 'Defensive Rating', 'sl': 'Tournament Wins'}\n",
    "\n",
    "    source = ColumnDataSource(data=reg)\n",
    "\n",
    "    p = figure(x_axis_label=label['xl'], y_axis_label=label['yl'])\n",
    "\n",
    "    mapper = LinearColorMapper(palette=Viridis256, low=min(reg['c']),\n",
    "                               high=max(reg['c']))\n",
    "    color_bar = ColorBar(color_mapper=mapper,\n",
    "                         location=(0, 0),\n",
    "                         ticker=BasicTicker())\n",
    "    p.add_layout(color_bar, 'right')\n",
    "\n",
    "    p.scatter(x='x', y='y', size=10,\n",
    "              fill_color=transform('c', mapper),\n",
    "              source=source)\n",
    "    p.add_tools(HoverTool(\n",
    "        tooltips=[('Name', '@{TeamName}'), ('Tournament Wins', '@{TOURNWINS}'), ('Regular Season Wins', '@{WINS}'),\n",
    "                  ('Regular Season Losses', '@{LOSSES}'),\n",
    "                  (\"Team ID\", '@{TeamID}')]))\n",
    "\n",
    "    maps = {}\n",
    "    for x in reg:\n",
    "        if x == 'TeamName' or x == 'TeamID':\n",
    "            continue\n",
    "        if '_' in x:\n",
    "            continue\n",
    "        maps[x] = LinearColorMapper(palette=Viridis256, low=min(reg[x]),\n",
    "                                    high=max(reg[x]))\n",
    "\n",
    "    callbackX = CustomJS(args=dict(source=source, label=label, axis=p.xaxis[0]), code=\"\"\"\n",
    "                console.log(label['xl']);\n",
    "                const data = source.data;\n",
    "                source.data['x'] = data[this.item]\n",
    "                label['xl'] = this.item;\n",
    "                axis.axis_label = this.item;\n",
    "                source.change.emit();\n",
    "\n",
    "                console.log('dropdown: ' + this.item + source.data['x'], this.toString())  \n",
    "            \"\"\")\n",
    "\n",
    "    callbackY = CustomJS(args=dict(source=source, label=label, axis=p.yaxis[0]), code=\"\"\"\n",
    "                    const data = source.data;\n",
    "                    source.data['y'] = data[this.item];\n",
    "                    source.change.emit();\n",
    "                    label['yl'] = this.item;\n",
    "                    axis.axis_label = this.item;\n",
    "                    console.log('dropdown: ' + this.item + source.data['y'], this.toString())  \n",
    "                \"\"\")\n",
    "    val = 1\n",
    "\n",
    "    callbackC = CustomJS(args=dict(source=source, mapper=mapper, maps=maps, label=label), code=\"\"\"\n",
    "                    const data = source.data;\n",
    "                    source.data['c'] = data[this.item];\n",
    "                    mapper.low = maps[this.item].low;\n",
    "                    mapper.high = maps[this.item].high;\n",
    "\n",
    "                    source.change.emit();\n",
    "                    mapper.change.emit();\n",
    "                    console.log('dropdown: ' + mapper.palette + maps, this.toString())  \n",
    "                \"\"\")\n",
    "\n",
    "    callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "            const data = source.data;\n",
    "            for (let i = 0; i < 149; i++) {\n",
    "                data['s'][i] = data['s'][i]*0.01;\n",
    "            }\n",
    "\n",
    "            source.change.emit();\n",
    "        \"\"\")\n",
    "\n",
    "    dropdownX = Dropdown(label=\"Change X\", button_type=\"warning\", menu=menu)\n",
    "    dropdownX.js_on_event(\"menu_item_click\", callbackX)\n",
    "    dropdownY = Dropdown(label=\"Change Y\", button_type=\"warning\", menu=menu)\n",
    "    dropdownY.js_on_event(\"menu_item_click\", callbackY)\n",
    "    dropdownC = Dropdown(label=\"Change Color\", button_type=\"warning\", menu=menu)\n",
    "    dropdownC.js_on_event(\"menu_item_click\", callbackC)\n",
    "    button = Button(label=\"Divide by 10!\", button_type=\"success\")\n",
    "    button.js_on_click(callback)\n",
    "\n",
    "\n",
    "    layout = column(dropdownX, dropdownY, dropdownC, p)\n",
    "\n",
    "    show(layout)\n",
    "    return reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071bd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the training data for my xgboost to input. It takes team 1s season averages and substracts\n",
    "# team 2s averages from it to get a vector of every stat. So if PPG is -8 that means on average team 1\n",
    "# scores 8 less points a game than team 2. The motivation behind this was to reduce the dimensionality\n",
    "# without running any algorithms which may result in a loss of interpretability (e.g. PCA). I also add\n",
    "# some randomization as to which team wins, otherwise team 1 would be the winner in every data point.\n",
    "def make_training_data(csvs, file):\n",
    "    szns = np.append(np.arange(2003, 2019, 1), [2021, 2022])\n",
    "    dataset = {}\n",
    "    c = 0\n",
    "    for i in szns:\n",
    "        print(i)\n",
    "        temp = calculate_averages(i, csvs, file)\n",
    "        training_data_cols = temp.columns[-35:].values.tolist()\n",
    "        training_data_cols.append('Team1')\n",
    "        training_data_cols.append('Team2')\n",
    "        training_data_cols.append('Team1Wins?')\n",
    "        training_data_cols.append('Team1Name')\n",
    "        training_data_cols.append('Team2Name')\n",
    "        tourNCAA = csvs['MNCAATourneyCompactResults.csv']\n",
    "        tourNCAA_s = tourNCAA.loc[tourNCAA['Season'] == i]\n",
    "        tourSec = csvs['MSecondaryTourneyCompactResults.csv']\n",
    "        tourSec_s = tourSec.loc[tourSec['Season'] == i]\n",
    "        dataset[i] = []\n",
    "        team_names = csvs['MTeams.csv']\n",
    "\n",
    "        for index, row in tourNCAA_s.iterrows():\n",
    "            a = temp.loc[temp['TeamID'] == row['WTeamID']].iloc[:, -35:]\n",
    "            b = temp.loc[temp['TeamID'] == row['LTeamID']].iloc[:, -35:]\n",
    "            num1 = random.randint(0, 1)\n",
    "            if num1 == 1:\n",
    "                x = (a.values - b.values).tolist()[0]\n",
    "                x = [i * -1 for i in x]\n",
    "                x.append(row['LTeamID'])\n",
    "                x.append(row['WTeamID'])\n",
    "                x.append(0)\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['LTeamID']].iloc[:, 1].values[0])\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['WTeamID']].iloc[:, 1].values[0])\n",
    "            else :\n",
    "                x = (a.values - b.values).tolist()[0]\n",
    "                x.append(row['WTeamID'])\n",
    "                x.append(row['LTeamID'])\n",
    "                x.append(1)\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['WTeamID']].iloc[:, 1].values[0])\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['LTeamID']].iloc[:, 1].values[0])\n",
    "            dataset[i].append(x)\n",
    "        for index, row in tourSec_s.iterrows():\n",
    "            # print(row['c1'], row['c2'])\n",
    "            a = temp.loc[temp['TeamID'] == row['WTeamID']].iloc[:, -35:]\n",
    "            b = temp.loc[temp['TeamID'] == row['LTeamID']].iloc[:, -35:]\n",
    "            num1 = random.randint(0, 1)\n",
    "            if num1 == 1:\n",
    "                x = (a.values - b.values).tolist()[0]\n",
    "                x = [i * -1 for i in x]\n",
    "                x.append(row['LTeamID'])\n",
    "                x.append(row['WTeamID'])\n",
    "                x.append(0)\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['LTeamID']].iloc[:, 1].values[0])\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['WTeamID']].iloc[:, 1].values[0])\n",
    "            else :\n",
    "                x = (a.values - b.values).tolist()[0]\n",
    "                x.append(row['WTeamID'])\n",
    "                x.append(row['LTeamID'])\n",
    "                x.append(1)\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['WTeamID']].iloc[:, 1].values[0])\n",
    "                x.append(team_names.loc[team_names['TeamID'] == row['LTeamID']].iloc[:, 1].values[0])\n",
    "            dataset[i].append(x)\n",
    "            #print(x)\n",
    "        if i == 2003:\n",
    "            c = np.array(dataset[i])\n",
    "        else:\n",
    "            c = np.concatenate((c, np.array(dataset[i])), axis=0)\n",
    "        print(c.shape)\n",
    "    return pd.DataFrame(data=c, columns=training_data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eed8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the xgboost classifier. \n",
    "def xgboostclassifier(training):\n",
    "    #data = training\n",
    "    # Split the data\n",
    "    #test = data.iloc[2105:, ]\n",
    "    #train = data.iloc[:2104, ]\n",
    "    #X_train = train.iloc[:, 0:-5].values\n",
    "    #y_train = train.iloc[:, -3].values\n",
    "    #X_test = test.iloc[:, 0:-5].values\n",
    "    #y_test = test.iloc[:, -3].values\n",
    "    # Create classification matrices\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(training.iloc[:, 0:-5].values, training.iloc[:, -3].values, test_size=0.05, random_state=1)\n",
    "\n",
    "    model = XGBRegressor(n_estimators=500, eta=0.01)\n",
    "    evalset = [(X_train, y_train), (X_test, y_test)]\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, eval_metric='rmse', eval_set=evalset)\n",
    "    # make predictions for test data\n",
    "    yhat = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, yhat)\n",
    "    print('MSE: %.3f' % score)\n",
    "    # retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    # plot learning curves\n",
    "    pyplot.plot(results['validation_0']['rmse'], label='train')\n",
    "    pyplot.plot(results['validation_1']['rmse'], label='test')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    #y_pred = model.predict(X_test)\n",
    "    #predictions = [round(value) for value in y_pred]\n",
    "    #for i in range(129):\n",
    "    #    print('%s => %f (expected %d)' % (test.iloc[i, -2:].tolist(), predictions[i], y_test[i]))\n",
    "    #accuracy = accuracy_score(y_test, predictions)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb20993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file MNCAATourneyDetailedResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object'), it has shape (1248, 34)\n",
      "Read file WNCAATourneySlots.csv, it has columns Index(['Season', 'Slot', 'StrongSeed', 'WeakSeed'], dtype='object'), it has shape (1646, 4)\n",
      "Read file MNCAATourneyCompactResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT'],\n",
      "      dtype='object'), it has shape (2384, 8)\n",
      "Read file MSeasons.csv, it has columns Index(['Season', 'DayZero', 'RegionW', 'RegionX', 'RegionY', 'RegionZ'], dtype='object'), it has shape (39, 6)\n",
      "Read file WTeams.csv, it has columns Index(['TeamID', 'TeamName'], dtype='object'), it has shape (375, 2)\n",
      "Read file MRegularSeasonDetailedResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object'), it has shape (107634, 34)\n",
      "Read file WNCAATourneyDetailedResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object'), it has shape (760, 34)\n",
      "Read file MNCAATourneySlots.csv, it has columns Index(['Season', 'Slot', 'StrongSeed', 'WeakSeed'], dtype='object'), it has shape (2452, 4)\n",
      "Read file MGameCities.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'LTeamID', 'CRType', 'CityID'], dtype='object'), it has shape (75187, 6)\n",
      "Read file MConferenceTourneyGames.csv, it has columns Index(['Season', 'ConfAbbrev', 'DayNum', 'WTeamID', 'LTeamID'], dtype='object'), it has shape (6189, 5)\n",
      "Read file WNCAATourneyCompactResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT'],\n",
      "      dtype='object'), it has shape (1516, 8)\n",
      "Read file WSeasons.csv, it has columns Index(['Season', 'DayZero', 'RegionW', 'RegionX', 'RegionY', 'RegionZ'], dtype='object'), it has shape (26, 6)\n",
      "Read file Cities.csv, it has columns Index(['CityID', 'City', 'State'], dtype='object'), it has shape (472, 3)\n",
      "Read file WRegularSeasonCompactResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT'],\n",
      "      dtype='object'), it has shape (126173, 8)\n",
      "Read file WTeamSpellings.csv, it has columns Index(['TeamNameSpelling', 'TeamID'], dtype='object'), it has shape (1157, 2)\n",
      "Read file WRegularSeasonDetailedResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object'), it has shape (70783, 34)\n",
      "Read file MRegularSeasonCompactResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT'],\n",
      "      dtype='object'), it has shape (181682, 8)\n",
      "Read file WNCAATourneySeeds.csv, it has columns Index(['Season', 'Seed', 'TeamID'], dtype='object'), it has shape (1608, 3)\n",
      "Read file MNCAATourneySeedRoundSlots.csv, it has columns Index(['Seed', 'GameRound', 'GameSlot', 'EarlyDayNum', 'LateDayNum'], dtype='object'), it has shape (720, 5)\n",
      "Read file WTeamConferences.csv, it has columns Index(['Season', 'TeamID', 'ConfAbbrev'], dtype='object'), it has shape (8768, 3)\n",
      "Read file MMasseyOrdinals_thru_Season2023_Day128.csv, it has columns Index(['Season', 'RankingDayNum', 'SystemName', 'TeamID', 'OrdinalRank'], dtype='object'), it has shape (4922512, 5)\n",
      "Read file MTeamConferences.csv, it has columns Index(['Season', 'TeamID', 'ConfAbbrev'], dtype='object'), it has shape (12662, 3)\n",
      "Read file MTeamCoaches.csv, it has columns Index(['Season', 'TeamID', 'FirstDayNum', 'LastDayNum', 'CoachName'], dtype='object'), it has shape (12799, 5)\n",
      "Read file SampleSubmission2023.csv, it has columns Index(['ID', 'Pred'], dtype='object'), it has shape (130683, 2)\n",
      "Read file Conferences.csv, it has columns Index(['ConfAbbrev', 'Description'], dtype='object'), it has shape (51, 2)\n",
      "Read file MTeams.csv, it has columns Index(['TeamID', 'TeamName', 'FirstD1Season', 'LastD1Season'], dtype='object'), it has shape (377, 4)\n",
      "Read file WGameCities.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'LTeamID', 'CRType', 'CityID'], dtype='object'), it has shape (71436, 6)\n",
      "Read file MNCAATourneySeeds.csv, it has columns Index(['Season', 'Seed', 'TeamID'], dtype='object'), it has shape (2490, 3)\n",
      "Read file MSecondaryTourneyTeams.csv, it has columns Index(['Season', 'SecondaryTourney', 'TeamID'], dtype='object'), it has shape (1732, 3)\n",
      "Read file MTeamSpellings.csv, it has columns Index(['TeamNameSpelling', 'TeamID'], dtype='object'), it has shape (1164, 2)\n",
      "Read file MSecondaryTourneyCompactResults.csv, it has columns Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'SecondaryTourney'],\n",
      "      dtype='object'), it has shape (1710, 9)\n",
      "2003\n",
      "(104, 40)\n",
      "2004\n",
      "(207, 40)\n",
      "2005\n",
      "(310, 40)\n",
      "2006\n",
      "(413, 40)\n",
      "2007\n",
      "(508, 40)\n",
      "2008\n",
      "(620, 40)\n",
      "2009\n",
      "(747, 40)\n",
      "2010\n",
      "(873, 40)\n",
      "2011\n",
      "(1011, 40)\n",
      "2012\n",
      "(1157, 40)\n",
      "2013\n",
      "(1303, 40)\n",
      "2014\n",
      "(1449, 40)\n",
      "2015\n",
      "(1594, 40)\n",
      "2016\n",
      "(1741, 40)\n",
      "2017\n",
      "(1881, 40)\n",
      "2018\n",
      "(2015, 40)\n",
      "2021\n",
      "(2104, 40)\n",
      "2022\n",
      "(2234, 40)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=PerformanceWarning)\n",
    "csvs = load_data()\n",
    "training_data = make_training_data(csvs, 'MRegularSeasonDetailedResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f50ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf622c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0a742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5735644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
